{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seventheli/anaconda/lib/python3.8/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.8.0` and `torch==1.10.2+cu102` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "from IPython import display\n",
    "from memory import Memory\n",
    "from utils import preprocess\n",
    "from model.simple_stack import SimpleStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the algorithm\n",
    "#### Update Network\n",
    "* Draw batches of tuples from the replay buffer: $(\\phi,r,a,\\phi')$.\n",
    "* Define the following loss\n",
    "$$\\Large(\\small Q(\\phi,a,\\theta)-r-Q(\\phi',argmax_{a'}Q(\\phi',a',\\theta),\\theta^-)\\Large)^2$$\n",
    "* Where $\\theta^-$ is the parameter of the target network.( Set $Q(\\phi',a',\\theta^-)$ to zero if $\\phi$ is the preprocessed termination state). \n",
    "* Update the $\\theta$\n",
    "* Update the $\\theta^-$ once in a while\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# frame channel\n",
    "channel = 1\n",
    "# The size of the batch to learn the Q-function\n",
    "batch_size = 16\n",
    "# Resize the raw input frame to square frame of size 80 by 80\n",
    "image_size = 84\n",
    "# Skip 4-1 raw frames between steps\n",
    "skip_frame = 4\n",
    "# Skip 4-1 raw frames between skipped frames\n",
    "internal_skip_frame = 4\n",
    "# The size of replay buffer; set it to size of your memory (.5M for 50G available memory)\n",
    "replay_buffer_size = 100000\n",
    "# With Freq of 1/4-step update the Q-network\n",
    "learning_frequency = 4\n",
    "# Each state is formed as a concatenation 4 step frames [f(t-12),f(t-8),f(t-4),f(t)]\n",
    "frame_len = 4\n",
    "# Update the target network each 10000 steps\n",
    "target_update = 10000\n",
    "# Minimum level of stochasticity of policy (epsilon)-greedy\n",
    "epsilon_min = 0.01\n",
    "# The number of step it take to linearly anneal the epsilon to it min value\n",
    "annealing_end = 1000000.\n",
    "# The discount factor\n",
    "gamma = 0.99\n",
    "# Start to back propagated through the network, learning starts\n",
    "replay_start_size = 50000\n",
    "# Run uniform policy for first 30 times step of the beginning of the game\n",
    "no_op_max = 8\n",
    "# Number episode to run the algorithm\n",
    "num_episode = 10000000\n",
    "max_frame = 200000000\n",
    "# RMSprop learning rate\n",
    "lr = 0.00025\n",
    "# RMSprop gamma1\n",
    "gamma1 = 0.95\n",
    "# RMSprop gamma2\n",
    "gamma2 = 0.95\n",
    "# RMSprop epsilon bias\n",
    "rms_eps = 0.01\n",
    "# Enables gpu if available, if not, set it to mx.cpu()\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'AssaultNoFrameskip-v4'\n",
    "env = gym.make(env_name)\n",
    "num_action = env.action_space.n\n",
    "manualSeed = 1\n",
    "mx.random.seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = SimpleStack(env.action_space.n, frame_len, channel=channel)\n",
    "dqn.collect_params().initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "trainer = gluon.Trainer(dqn.collect_params(), 'RMSProp',\n",
    "                        {'learning_rate': lr, 'gamma1': gamma1, 'gamma2': gamma2, 'epsilon': rms_eps, 'centered': True})\n",
    "dqn.collect_params().zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dqn = SimpleStack(env.action_space.n, frame_len, channel=channel)\n",
    "target_dqn.collect_params().initialize(mx.init.Normal(0.02), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rew_clipper(rew_clip):\n",
    "    if rew_clip > 0.:\n",
    "        return 1.\n",
    "    elif rew_clip < 0.:\n",
    "        return -1.\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def render_image(frame, render):\n",
    "    if render:\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = mx.gluon.loss.L2Loss(batch_axis=0)\n",
    "# Counts the number of steps so far\n",
    "frame_counter = 0.\n",
    "# Counts the number of annealing steps\n",
    "annealing_count = 0.\n",
    "# Counts the number episodes so far\n",
    "epis_count = 0.\n",
    "# Initialize the replay buffer\n",
    "replay_memory = Memory(replay_buffer_size)\n",
    "tot_clipped_reward = []\n",
    "tot_reward = []\n",
    "frame_count_record = []\n",
    "moving_average_clipped = 0.\n",
    "moving_average = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis[1150],eps[0.7573],durat[208],fnum=292650, cum_cl_rew = 9, cum_rew = 189.0000,tot_cl = 12.8500 , tot = 269.8500\n",
      "epis[1200],eps[0.7455],durat[213],fnum=304538, cum_cl_rew = 9, cum_rew = 189.0000,tot_cl = 12.6900 , tot = 266.3800\n",
      "epis[1250],eps[0.7340],durat[200],fnum=316044, cum_cl_rew = 13, cum_rew = 273.0000,tot_cl = 12.5400 , tot = 263.2300\n",
      "epis[1300],eps[0.7219],durat[176],fnum=328094, cum_cl_rew = 9, cum_rew = 189.0000,tot_cl = 12.6700 , tot = 266.0700\n",
      "epis[1350],eps[0.7096],durat[319],fnum=340398, cum_cl_rew = 11, cum_rew = 231.0000,tot_cl = 12.9900 , tot = 272.7900\n",
      "epis[1400],eps[0.6977],durat[267],fnum=352287, cum_cl_rew = 18, cum_rew = 378.0000,tot_cl = 12.8800 , tot = 270.4800\n",
      "epis[1450],eps[0.6865],durat[195],fnum=363505, cum_cl_rew = 13, cum_rew = 273.0000,tot_cl = 12.8000 , tot = 268.8000\n",
      "epis[1500],eps[0.6743],durat[259],fnum=375701, cum_cl_rew = 16, cum_rew = 336.0000,tot_cl = 13.0600 , tot = 274.2600\n",
      "epis[1550],eps[0.6622],durat[195],fnum=387832, cum_cl_rew = 8, cum_rew = 168.0000,tot_cl = 13.3700 , tot = 280.7700\n",
      "epis[1600],eps[0.6510],durat[294],fnum=398966, cum_cl_rew = 17, cum_rew = 357.0000,tot_cl = 13.0900 , tot = 274.8900\n",
      "epis[1650],eps[0.6393],durat[252],fnum=410662, cum_cl_rew = 14, cum_rew = 294.0000,tot_cl = 13.1700 , tot = 276.5700\n",
      "epis[1700],eps[0.6276],durat[141],fnum=422434, cum_cl_rew = 9, cum_rew = 189.0000,tot_cl = 13.7000 , tot = 287.7000\n",
      "epis[1750],eps[0.6154],durat[254],fnum=434593, cum_cl_rew = 13, cum_rew = 273.0000,tot_cl = 13.7700 , tot = 289.1700\n",
      "epis[1800],eps[0.6037],durat[228],fnum=446270, cum_cl_rew = 14, cum_rew = 294.0000,tot_cl = 14.0800 , tot = 295.5700\n",
      "epis[1850],eps[0.5921],durat[156],fnum=457939, cum_cl_rew = 9, cum_rew = 189.0000,tot_cl = 14.3000 , tot = 300.1900\n",
      "epis[1900],eps[0.5800],durat[117],fnum=470040, cum_cl_rew = 8, cum_rew = 168.0000,tot_cl = 14.0900 , tot = 295.8900\n",
      "epis[1950],eps[0.5677],durat[268],fnum=482278, cum_cl_rew = 18, cum_rew = 378.0000,tot_cl = 14.5900 , tot = 306.3900\n",
      "epis[2000],eps[0.5566],durat[199],fnum=493442, cum_cl_rew = 9, cum_rew = 189.0000,tot_cl = 14.5600 , tot = 305.7600\n",
      "epis[2050],eps[0.5442],durat[245],fnum=505828, cum_cl_rew = 19, cum_rew = 399.0000,tot_cl = 14.9900 , tot = 314.7900\n",
      "epis[2100],eps[0.5322],durat[258],fnum=517816, cum_cl_rew = 15, cum_rew = 315.0000,tot_cl = 16.0500 , tot = 337.0500\n",
      "epis[2150],eps[0.5207],durat[223],fnum=529347, cum_cl_rew = 17, cum_rew = 357.0000,tot_cl = 15.7800 , tot = 331.3800\n",
      "epis[2200],eps[0.5094],durat[200],fnum=540581, cum_cl_rew = 12, cum_rew = 252.0000,tot_cl = 15.2200 , tot = 319.6200\n",
      "epis[2250],eps[0.4974],durat[181],fnum=552577, cum_cl_rew = 17, cum_rew = 357.0000,tot_cl = 15.4300 , tot = 324.0300\n",
      "epis[2300],eps[0.4852],durat[208],fnum=564796, cum_cl_rew = 13, cum_rew = 273.0000,tot_cl = 16.6500 , tot = 349.6500\n",
      "epis[2350],eps[0.4732],durat[240],fnum=576808, cum_cl_rew = 18, cum_rew = 378.0000,tot_cl = 16.9400 , tot = 355.7400\n",
      "epis[2400],eps[0.4606],durat[267],fnum=589433, cum_cl_rew = 14, cum_rew = 294.0000,tot_cl = 16.7500 , tot = 351.7500\n",
      "epis[2450],eps[0.4480],durat[248],fnum=602004, cum_cl_rew = 19, cum_rew = 399.0000,tot_cl = 17.4900 , tot = 367.2900\n",
      "epis[2500],eps[0.4356],durat[307],fnum=614441, cum_cl_rew = 29, cum_rew = 609.0000,tot_cl = 17.6700 , tot = 371.0700\n",
      "epis[2550],eps[0.4231],durat[297],fnum=626908, cum_cl_rew = 16, cum_rew = 336.0000,tot_cl = 18.0000 , tot = 378.0000\n",
      "epis[2600],eps[0.4097],durat[321],fnum=640341, cum_cl_rew = 25, cum_rew = 525.0000,tot_cl = 19.2800 , tot = 404.8800\n",
      "epis[2650],eps[0.3967],durat[179],fnum=653345, cum_cl_rew = 18, cum_rew = 378.0000,tot_cl = 19.9900 , tot = 419.7900\n",
      "epis[2700],eps[0.3834],durat[259],fnum=666602, cum_cl_rew = 17, cum_rew = 357.0000,tot_cl = 19.8500 , tot = 416.7400\n",
      "epis[2750],eps[0.3687],durat[97],fnum=681307, cum_cl_rew = 8, cum_rew = 168.0000,tot_cl = 21.0500 , tot = 441.7200\n",
      "epis[2800],eps[0.3560],durat[471],fnum=694020, cum_cl_rew = 33, cum_rew = 693.0000,tot_cl = 20.9400 , tot = 439.5200\n",
      "epis[2850],eps[0.3422],durat[349],fnum=707791, cum_cl_rew = 31, cum_rew = 651.0000,tot_cl = 20.4400 , tot = 429.1300\n",
      "epis[2900],eps[0.3284],durat[298],fnum=721567, cum_cl_rew = 24, cum_rew = 504.0000,tot_cl = 22.2400 , tot = 466.4900\n",
      "epis[2950],eps[0.3140],durat[317],fnum=736022, cum_cl_rew = 28, cum_rew = 588.0000,tot_cl = 22.9300 , tot = 480.9800\n",
      "epis[3000],eps[0.2997],durat[310],fnum=750339, cum_cl_rew = 31, cum_rew = 651.0000,tot_cl = 22.8200 , tot = 478.8900\n",
      "epis[3050],eps[0.2838],durat[370],fnum=766159, cum_cl_rew = 34, cum_rew = 714.0000,tot_cl = 23.7300 , tot = 497.8900\n",
      "epis[3100],eps[0.2702],durat[337],fnum=779775, cum_cl_rew = 29, cum_rew = 609.0000,tot_cl = 24.3300 , tot = 510.6000\n",
      "epis[3150],eps[0.2559],durat[324],fnum=794074, cum_cl_rew = 30, cum_rew = 630.0000,tot_cl = 24.7600 , tot = 519.4100\n",
      "epis[3200],eps[0.2420],durat[169],fnum=807963, cum_cl_rew = 14, cum_rew = 294.0000,tot_cl = 25.2500 , tot = 529.1500\n",
      "epis[3250],eps[0.2282],durat[310],fnum=821811, cum_cl_rew = 33, cum_rew = 693.0000,tot_cl = 24.9100 , tot = 522.0100\n",
      "epis[3300],eps[0.2135],durat[407],fnum=836511, cum_cl_rew = 32, cum_rew = 672.0000,tot_cl = 25.5800 , tot = 536.3000\n",
      "epis[3350],eps[0.1982],durat[507],fnum=851841, cum_cl_rew = 37, cum_rew = 733.0000,tot_cl = 26.9900 , tot = 564.7000\n",
      "epis[3400],eps[0.1830],durat[298],fnum=866992, cum_cl_rew = 30, cum_rew = 630.0000,tot_cl = 28.6700 , tot = 596.6800\n",
      "epis[3450],eps[0.1681],durat[255],fnum=881950, cum_cl_rew = 26, cum_rew = 546.0000,tot_cl = 29.0900 , tot = 605.0600\n",
      "epis[3500],eps[0.1533],durat[154],fnum=896677, cum_cl_rew = 10, cum_rew = 210.0000,tot_cl = 28.7700 , tot = 600.4300\n",
      "epis[3550],eps[0.1399],durat[169],fnum=910132, cum_cl_rew = 16, cum_rew = 336.0000,tot_cl = 28.5700 , tot = 595.1300\n",
      "epis[3600],eps[0.1249],durat[323],fnum=925087, cum_cl_rew = 35, cum_rew = 724.0000,tot_cl = 29.8600 , tot = 617.9300\n",
      "epis[3650],eps[0.1086],durat[319],fnum=941391, cum_cl_rew = 33, cum_rew = 693.0000,tot_cl = 33.0800 , tot = 678.8400\n",
      "epis[3700],eps[0.0924],durat[740],fnum=957647, cum_cl_rew = 80, cum_rew = 1625.0000,tot_cl = 35.0600 , tot = 715.1400\n",
      "epis[3750],eps[0.0758],durat[250],fnum=974192, cum_cl_rew = 33, cum_rew = 693.0000,tot_cl = 37.5000 , tot = 760.0000\n",
      "epis[3800],eps[0.0578],durat[350],fnum=992204, cum_cl_rew = 34, cum_rew = 714.0000,tot_cl = 40.9400 , tot = 825.0900\n",
      "epis[3850],eps[0.0364],durat[435],fnum=1013593, cum_cl_rew = 52, cum_rew = 982.0000,tot_cl = 45.2200 , tot = 912.8800\n",
      "epis[3900],eps[0.0169],durat[328],fnum=1033074, cum_cl_rew = 43, cum_rew = 837.0000,tot_cl = 46.7100 , tot = 945.2700\n",
      "epis[3950],eps[0.0100],durat[279],fnum=1052435, cum_cl_rew = 31, cum_rew = 640.0000,tot_cl = 46.6800 , tot = 943.8700\n",
      "epis[4000],eps[0.0100],durat[386],fnum=1075386, cum_cl_rew = 50, cum_rew = 973.0000,tot_cl = 50.8200 , tot = 1022.7800\n",
      "epis[4050],eps[0.0100],durat[455],fnum=1099060, cum_cl_rew = 55, cum_rew = 1144.0000,tot_cl = 55.9400 , tot = 1126.7800\n",
      "epis[4100],eps[0.0100],durat[272],fnum=1124975, cum_cl_rew = 41, cum_rew = 817.0000,tot_cl = 60.6000 , tot = 1226.6200\n",
      "epis[4150],eps[0.0100],durat[543],fnum=1147763, cum_cl_rew = 74, cum_rew = 1499.0000,tot_cl = 60.4900 , tot = 1223.9800\n",
      "epis[4200],eps[0.0100],durat[288],fnum=1169182, cum_cl_rew = 43, cum_rew = 870.0000,tot_cl = 56.8400 , tot = 1148.9800\n",
      "epis[4250],eps[0.0100],durat[602],fnum=1197264, cum_cl_rew = 78, cum_rew = 1550.0000,tot_cl = 64.2900 , tot = 1302.1300\n",
      "epis[4300],eps[0.0100],durat[278],fnum=1219683, cum_cl_rew = 33, cum_rew = 693.0000,tot_cl = 66.9500 , tot = 1357.3300\n",
      "epis[4350],eps[0.0100],durat[309],fnum=1245314, cum_cl_rew = 40, cum_rew = 807.0000,tot_cl = 64.0400 , tot = 1299.6300\n",
      "epis[4400],eps[0.0100],durat[405],fnum=1267294, cum_cl_rew = 55, cum_rew = 1100.0000,tot_cl = 61.6500 , tot = 1254.3900\n",
      "epis[4450],eps[0.0100],durat[328],fnum=1292294, cum_cl_rew = 42, cum_rew = 816.0000,tot_cl = 61.6000 , tot = 1249.4900\n",
      "epis[4500],eps[0.0100],durat[323],fnum=1317187, cum_cl_rew = 41, cum_rew = 828.0000,tot_cl = 65.2900 , tot = 1316.8600\n",
      "epis[4550],eps[0.0100],durat[308],fnum=1339433, cum_cl_rew = 45, cum_rew = 901.0000,tot_cl = 60.1600 , tot = 1215.6200\n",
      "epis[4600],eps[0.0100],durat[479],fnum=1358692, cum_cl_rew = 71, cum_rew = 1414.0000,tot_cl = 54.8700 , tot = 1110.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis[4650],eps[0.0100],durat[269],fnum=1383363, cum_cl_rew = 40, cum_rew = 807.0000,tot_cl = 59.9600 , tot = 1208.6700\n",
      "epis[4700],eps[0.0100],durat[691],fnum=1410552, cum_cl_rew = 94, cum_rew = 1875.0000,tot_cl = 68.8000 , tot = 1390.2400\n",
      "epis[4750],eps[0.0100],durat[270],fnum=1434697, cum_cl_rew = 41, cum_rew = 850.0000,tot_cl = 67.5800 , tot = 1369.3500\n",
      "epis[4800],eps[0.0100],durat[341],fnum=1458588, cum_cl_rew = 51, cum_rew = 972.0000,tot_cl = 64.4200 , tot = 1306.4000\n"
     ]
    }
   ],
   "source": [
    "# Whether to render Frames and show the game\n",
    "_render = False\n",
    "while epis_count < max_frame:\n",
    "    cum_clipped_reward = 0\n",
    "    cum_reward = 0\n",
    "    next_frame = env.reset()\n",
    "    state, current_frame = preprocess(next_frame, image_size, channel, frame_len, initial_state=True)\n",
    "    t = 0.\n",
    "    done = False\n",
    "    initial_state = True\n",
    "    while not done:\n",
    "        previous_state = state\n",
    "        # show the frame\n",
    "        render_image(next_frame, _render)\n",
    "        sample = random.random()\n",
    "        if frame_counter > replay_start_size:\n",
    "            annealing_count += 1\n",
    "        if frame_counter == replay_start_size:\n",
    "            print('annealing and learning are started ')\n",
    "        eps = np.maximum(1. - annealing_count / annealing_end, epsilon_min)\n",
    "\n",
    "        effective_eps = eps\n",
    "        if t < no_op_max:\n",
    "            effective_eps = 1.\n",
    "        # epsilon greedy policy\n",
    "        if sample < effective_eps:\n",
    "            action = random.randint(0, num_action - 1)\n",
    "        else:\n",
    "            data = [nd.array(state.reshape([1, frame_len, image_size, image_size]), ctx), nd.array([100 - t], ctx)]\n",
    "            action = int(nd.argmax(dqn(*data), axis=1).as_in_context(mx.cpu()).asscalar())\n",
    "        # Skip frame\n",
    "        rew = 0\n",
    "        for skip in range(skip_frame - 1):\n",
    "            next_frame, reward, done, _ = env.step(action)\n",
    "            render_image(next_frame, _render)\n",
    "            cum_clipped_reward += rew_clipper(reward)\n",
    "            rew += reward\n",
    "            for internal_skip in range(internal_skip_frame - 1):\n",
    "                _, reward, done, _ = env.step(action)\n",
    "                cum_clipped_reward += rew_clipper(reward)\n",
    "                rew += reward\n",
    "\n",
    "        next_frame_new, reward, done, _ = env.step(action)\n",
    "        render_image(next_frame, _render)\n",
    "        cum_clipped_reward += rew_clipper(reward)\n",
    "        rew += reward\n",
    "        cum_reward += rew\n",
    "\n",
    "        # Reward clipping\n",
    "\n",
    "        reward = rew_clipper(rew)\n",
    "        next_frame = np.maximum(next_frame_new, next_frame)\n",
    "        state, current_frame = preprocess(next_frame, image_size, channel, frame_len, current_state=state)\n",
    "        replay_memory.push(previous_state, action, state, reward, done, 100 -t)\n",
    "\n",
    "        # Train\n",
    "        if frame_counter > replay_start_size:\n",
    "            if frame_counter % learning_frequency == 0:\n",
    "                batch = replay_memory.sample(batch_size, ctx)\n",
    "                batch_state = batch.state\n",
    "                batch_state_next = batch.state_next\n",
    "                batch_battery  = batch.battery\n",
    "                batch_reward = batch.reward\n",
    "                batch_action = batch.action.astype('uint8')\n",
    "                batch_done = batch.finish\n",
    "                with autograd.record():\n",
    "                    argmax_Q = nd.argmax(dqn(batch_state_next, batch_battery),axis = 1).astype('uint8')\n",
    "                    Q_sp = nd.pick(target_dqn(batch.state_next, batch.battery),argmax_Q,1)\n",
    "                    Q_sp = Q_sp*(nd.ones(batch_size,ctx = ctx)-batch_done)\n",
    "                    Q_s_array = dqn(batch_state, batch_battery)\n",
    "                    Q_s = nd.pick(Q_s_array,batch_action,1)\n",
    "                    loss = nd.mean(loss_f(Q_s ,  (batch_reward + gamma *Q_sp)))\n",
    "                loss.backward()\n",
    "                trainer.step(batch_size)\n",
    "        t += 1\n",
    "        frame_counter += 1\n",
    "        # Save the model and update Target model\n",
    "        if frame_counter >replay_start_size:\n",
    "            if frame_counter % target_update == 0:\n",
    "                check_point = frame_counter / (target_update * 100)\n",
    "                file_name = './data/target_%s_%d' % (env_name, int(check_point))\n",
    "                dqn.save_parameters(file_name)\n",
    "                target_dqn.load_parameters(file_name, ctx)\n",
    "        if done:\n",
    "            if epis_count % 50. == 0. :\n",
    "                print('epis[%d],eps[%.4f],durat[%d],fnum=%d, cum_cl_rew = %d, cum_rew = %.4f,tot_cl = %.4f , tot = %.4f'\\\n",
    "                  %(epis_count,eps,t+1,frame_counter,cum_clipped_reward,cum_reward,moving_average_clipped,moving_average))\n",
    "    epis_count += 1\n",
    "    tot_clipped_reward = np.append(tot_clipped_reward, cum_clipped_reward)\n",
    "    tot_reward = np.append(tot_reward, cum_reward)\n",
    "    frame_count_record = np.append(frame_count_record,frame_counter)\n",
    "    if epis_count > 100.:\n",
    "        moving_average_clipped = np.mean(tot_clipped_reward[int(epis_count)-1-100:int(epis_count)-1])\n",
    "        moving_average = np.mean(tot_reward[int(epis_count)-1-100:int(epis_count)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the overall performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epis_count = epis_count - 0\n",
    "bandwidth = 100  # Moving average bandwidth\n",
    "total_clipped = np.zeros(int(num_epis_count) - bandwidth)\n",
    "total_rew = np.zeros(int(num_epis_count) - bandwidth)\n",
    "for i in range(int(num_epis_count) - bandwidth):\n",
    "    total_clipped[i] = np.sum(tot_clipped_reward[i:i + bandwidth]) / bandwidth\n",
    "    total_rew[i] = np.sum(tot_reward[i:i + bandwidth]) / bandwidth\n",
    "t = np.arange(int(num_epis_count) - bandwidth)\n",
    "fig = plt.figure()\n",
    "belplt = plt.plot(t, total_rew[0:int(num_epis_count) - bandwidth], \"r\", label=\"Return\")\n",
    "plt.legend()  #handles[likplt,belplt])\n",
    "print('Running after %d number of episodes' % epis_count)\n",
    "plt.xlabel(\"Number of episode\")\n",
    "plt.ylabel(\"Average Reward per episode\")\n",
    "plt.show()\n",
    "fig.savefig('Assualt_DDQN.png')\n",
    "fig = plt.figure()\n",
    "likplt = plt.plot(t, total_clipped[0:num_episode - bandwidth], \"b\", label=\"Clipped Return\")\n",
    "plt.legend()  #handles[likplt,belplt])\n",
    "plt.xlabel(\"Number of episode\")\n",
    "plt.ylabel(\"Average clipped Reward per episode\")\n",
    "plt.show()\n",
    "fig.savefig('DDQN_Clipped.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
