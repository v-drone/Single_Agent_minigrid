{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import time\n",
    "import logging\n",
    "import pickle\n",
    "import gym_minigrid\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "from IPython import display\n",
    "from memory import Memory\n",
    "from utils import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the algorithm\n",
    "#### Update Network\n",
    "* Draw batches of tuples from the replay buffer: $(\\phi,r,a,\\phi')$.\n",
    "* Define the following loss\n",
    "$$\\Large(\\small Q(\\phi,a,\\theta)-r-Q(\\phi',argmax_{a'}Q(\\phi',a',\\theta),\\theta^-)\\Large)^2$$\n",
    "* Where $\\theta^-$ is the parameter of the target network.( Set $Q(\\phi',a',\\theta^-)$ to zero if $\\phi$ is the preprocessed termination state). \n",
    "* Update the $\\theta$\n",
    "* Update the $\\theta^-$ once in a while\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_n\n",
    "model_n = 1\n",
    "# frame channel\n",
    "channel = 3\n",
    "# The size of the batch to learn the Q-function\n",
    "batch_size = 16\n",
    "# Resize the raw input frame to square frame of size 80 by 80\n",
    "image_size = 84\n",
    "# Skip 4-1 raw frames between steps\n",
    "skip_frame = 1\n",
    "# The size of replay buffer; set it to size of your memory (.5M for 50G available memory)\n",
    "replay_buffer_size = 100000\n",
    "# 50K * 16 Frame * 3 Channel = 38GB\n",
    "# With Freq of 1/ 2 step update the Q-network\n",
    "learning_frequency = 4\n",
    "# Each state is formed as a concatenation 4 step frames [f(t-12),f(t-8),f(t-4),f(t)]\n",
    "frame_len = 4\n",
    "# Update the target network each 10000 steps\n",
    "target_update = 10000\n",
    "# Minimum level of stochasticity of policy (epsilon)-greedy\n",
    "epsilon_min = 0.01\n",
    "# The number of step it take to linearly anneal the epsilon to it min value\n",
    "annealing_end = 1000000.\n",
    "# The discount factor\n",
    "gamma = 0.99\n",
    "# Start to back propagated through the network, learning starts\n",
    "replay_start_size = 50000\n",
    "# Run uniform policy for first 30 times step of the beginning of the game\n",
    "no_op_max = 4\n",
    "# Number episode to run the algorithm\n",
    "num_episode = 10000000\n",
    "max_frame = 2000000\n",
    "# learning rate\n",
    "lr = 0.0005\n",
    "# RMSprop epsilon bias\n",
    "rms_eps = 0.01\n",
    "# Enables gpu if available, if not, set it to mx.cpu()\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'MiniGrid-FourRooms-v0'\n",
    "env = gym.make(env_name)\n",
    "num_action = 3\n",
    "manualSeed = 1\n",
    "mx.random.seed(manualSeed)\n",
    "env_name = env_name + \"-Map-Frame_%d-Channel_%d_Model_%d\" %(frame_len, channel, model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn, rnn\n",
    "from mxnet import nd\n",
    "class SimpleStack(nn.Block):\n",
    "    def __init__(self, actions, frames, channel=3):\n",
    "        self.frames = frames\n",
    "        self.channel = channel\n",
    "        super(SimpleStack, self).__init__()\n",
    "        c = [64, 128, 128]\n",
    "        k = [8, 4, 3]\n",
    "        s = [4, 2, 1]\n",
    "        p = [0, 0, 0]\n",
    "        with self.name_scope():\n",
    "            self.map = nn.Sequential()\n",
    "            self.out = nn.Sequential()\n",
    "            with self.map.name_scope():\n",
    "                for i, j, x, y in zip(c, k, s, p):\n",
    "                    self.map.add(nn.Conv2D(channels=i, kernel_size=j, strides=x, padding=y, layout=\"NCHW\"))\n",
    "                    self.map.add(nn.Activation(\"tanh\"))\n",
    "                    self.map.add(nn.BatchNorm(axis=1, momentum=0.1, center=True))\n",
    "                self.map.add(nn.Flatten())\n",
    "            with self.out.name_scope():\n",
    "                self.out.add(nn.Dense(512, activation=\"tanh\"))\n",
    "                self.out.add(nn.Dense(actions))\n",
    "\n",
    "    def forward(self, memory, battery, *args):\n",
    "        _b, _c, _h, _w = memory.shape\n",
    "        # image part\n",
    "        _features = self.map(memory).reshape([_b, self.frames, -1])\n",
    "        return self.out(_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = SimpleStack(num_action, frame_len, channel=channel)\n",
    "dqn.collect_params().initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "trainer = gluon.Trainer(dqn.collect_params(), 'Adam',\n",
    "                        {'learning_rate': lr, \"wd\": 0.0001})\n",
    "dqn.collect_params().zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dqn = SimpleStack(num_action, frame_len, channel=channel)\n",
    "target_dqn.collect_params().initialize(mx.init.Normal(0.02), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn.load_parameters(\"./data/target_MiniGrid-FourRooms-v0-Map-Frame_4-Channel_3_Model_1_1\")\n",
    "# target_dqn.load_parameters(\"./data/target_MiniGrid-FourRooms-v0-Map-Frame_4-Channel_3_Model_1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = Memory(replay_buffer_size, frame_len, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = mx.gluon.loss.L2Loss(batch_axis=0)\n",
    "# Counts the number of steps so far\n",
    "frame_counter = 0.\n",
    "# Counts the number of annealing steps\n",
    "annealing_count = 0.\n",
    "# Counts the number episodes so far\n",
    "epis_count = 0.\n",
    "# Initialize the replay buffer\n",
    "tot_clipped_reward = []\n",
    "tot_reward = []\n",
    "frame_count_record = []\n",
    "tot_step = []\n",
    "average_clipped = 0.\n",
    "average = 0.\n",
    "last_clipped = 0\n",
    "last = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot_clipped_reward = np.load(\"tot_clipped_reward_%s_Model_1.npy\" % env_name).tolist()\n",
    "# tot_reward = np.load(\"tot_reward_%s_Model_1.npy\" % env_name).tolist()\n",
    "# frame_count_record = np.load(\"frame_count_record_%s_Model_1.npy\" % env_name).tolist()\n",
    "# t_record = np.load(\"t_record_%s_Model_1.npy\" % env_name).tolist()\n",
    "# frame_counter = len(tot_reward) * 80\n",
    "# annealing_count = len(tot_reward) * 80\n",
    "# epis_count = len(tot_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replay_memory = Memory(replay_buffer_size, frame_len, channel)\n",
    "# with open(\"./memory\", \"rb\") as f:\n",
    "#     _ = pickle.load(f)\n",
    "# for i in _:\n",
    "#     replay_memory.push(*i)\n",
    "#     del i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rew_clipper(row, history):\n",
    "    counter = 0\n",
    "    _ = list(reversed(history))[0]\n",
    "    for i in list(reversed(history))[1:]:\n",
    "        if i == _:\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return (row- 0.0001 * counter) * 100\n",
    "\n",
    "def render_image(frame, render):\n",
    "    if render:\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "state, current_frame = preprocess(env.render(False), image_size, channel, frame_len, initial_state=True)\n",
    "_ = current_frame.asnumpy().transpose([1,2,0])\n",
    "# _ = np.concatenate([current_frame.asnumpy(), current_frame.asnumpy(), current_frame.asnumpy()]).transpose([1,2,0])\n",
    "render_image(_, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis[0],eps[1.0000],durat[101],fnum=100,tot_cl=0.0000,tot=0.0000,last_cl=0.0000,last=0.0000\n",
      "epis[50],eps[1.0000],durat[94],fnum=4753,tot_cl=0.0000,tot=0.0000,last_cl=0.0000,last=0.0000\n",
      "epis[100],eps[1.0000],durat[96],fnum=9654,tot_cl=0.0000,tot=0.0000,last_cl=0.0000,last=0.0000\n",
      "epis[150],eps[1.0000],durat[98],fnum=14654,tot_cl=0.1693,tot=0.0308,last_cl=-1.8103,last=0.0099\n",
      "epis[200],eps[1.0000],durat[97],fnum=19410,tot_cl=0.7482,tot=0.0365,last_cl=-0.1178,last=0.0270\n",
      "epis[250],eps[1.0000],durat[98],fnum=24393,tot_cl=0.0754,tot=0.0303,last_cl=-0.0655,last=0.0295\n",
      "epis[300],eps[1.0000],durat[97],fnum=29153,tot_cl=0.4580,tot=0.0337,last_cl=-0.1224,last=0.0281\n",
      "epis[350],eps[1.0000],durat[97],fnum=33774,tot_cl=1.1048,tot=0.0402,last_cl=3.6784,last=0.0651\n",
      "epis[400],eps[1.0000],durat[97],fnum=38668,tot_cl=0.9407,tot=0.0387,last_cl=2.3886,last=0.0536\n",
      "epis[450],eps[1.0000],durat[97],fnum=43573,tot_cl=0.7463,tot=0.0365,last_cl=-0.5086,last=0.0237\n",
      "epis[500],eps[1.0000],durat[97],fnum=48545,tot_cl=0.4560,tot=0.0336,last_cl=-1.4824,last=0.0131\n",
      "annealing and learning are started tot = 0.0326\n",
      "epis[550],eps[0.9965],durat[98],fnum=53513,tot_cl=0.2202,tot=0.0312,last_cl=-2.1470,last=0.0074\n",
      "epis[600],eps[0.9916],durat[98],fnum=58416,tot_cl=0.1373,tot=0.0304,last_cl=-1.4563,last=0.0146\n",
      "epis[650],eps[0.9867],durat[98],fnum=63271,tot_cl=0.1456,tot=0.0304,last_cl=-0.2645,last=0.0258\n",
      "epis[700],eps[0.9818],durat[98],fnum=68164,tot_cl=0.0203,tot=0.0292,last_cl=-0.6820,last=0.0216\n",
      "epis[750],eps[0.9770],durat[98],fnum=73036,tot_cl=0.0977,tot=0.0298,last_cl=-0.2138,last=0.0261\n",
      "epis[800],eps[0.9724],durat[97],fnum=77595,tot_cl=0.5206,tot=0.0338,last_cl=4.0228,last=0.0663\n",
      "epis[850],eps[0.9676],durat[97],fnum=82383,tot_cl=0.5998,tot=0.0345,last_cl=4.3652,last=0.0698\n",
      "epis[900],eps[0.9627],durat[97],fnum=87268,tot_cl=0.5390,tot=0.0340,last_cl=0.6867,last=0.0354\n",
      "epis[950],eps[0.9579],durat[97],fnum=92118,tot_cl=0.5466,tot=0.0339,last_cl=0.0949,last=0.0288\n",
      "epis[1000],eps[0.9530],durat[97],fnum=96976,tot_cl=0.5279,tot=0.0337,last_cl=0.4274,last=0.0313\n",
      "epis[1050],eps[0.9481],durat[97],fnum=101899,tot_cl=0.4533,tot=0.0330,last_cl=-0.4333,last=0.0237\n",
      "epis[1100],eps[0.9433],durat[97],fnum=106682,tot_cl=0.5202,tot=0.0335,last_cl=0.4439,last=0.0315\n",
      "epis[1150],eps[0.9385],durat[97],fnum=111507,tot_cl=0.5430,tot=0.0337,last_cl=1.4850,last=0.0413\n",
      "epis[1200],eps[0.9336],durat[97],fnum=116415,tot_cl=0.4709,tot=0.0331,last_cl=-0.0719,last=0.0280\n",
      "epis[1250],eps[0.9286],durat[98],fnum=121412,tot_cl=0.3553,tot=0.0318,last_cl=-1.8029,last=0.0105\n",
      "epis[1300],eps[0.9239],durat[97],fnum=126073,tot_cl=0.5233,tot=0.0333,last_cl=1.1515,last=0.0368\n",
      "epis[1350],eps[0.9189],durat[98],fnum=131073,tot_cl=0.4097,tot=0.0321,last_cl=1.0898,last=0.0355\n",
      "epis[1400],eps[0.9141],durat[98],fnum=135913,tot_cl=0.4223,tot=0.0321,last_cl=-0.8905,last=0.0164\n",
      "epis[1450],eps[0.9093],durat[98],fnum=140750,tot_cl=0.4436,tot=0.0323,last_cl=0.9003,last=0.0351\n",
      "epis[1500],eps[0.9043],durat[98],fnum=145661,tot_cl=0.4079,tot=0.0320,last_cl=0.2060,last=0.0297\n",
      "epis[1550],eps[0.8996],durat[98],fnum=150447,tot_cl=0.4591,tot=0.0324,last_cl=0.6847,last=0.0333\n",
      "epis[1600],eps[0.8946],durat[98],fnum=155447,tot_cl=0.3607,tot=0.0314,last_cl=-0.3471,last=0.0223\n",
      "epis[1650],eps[0.8900],durat[97],fnum=160031,tot_cl=0.5049,tot=0.0327,last_cl=1.2149,last=0.0375\n",
      "epis[1700],eps[0.8851],durat[97],fnum=164945,tot_cl=0.4949,tot=0.0326,last_cl=2.6430,last=0.0522\n",
      "epis[1750],eps[0.8802],durat[97],fnum=169784,tot_cl=0.5114,tot=0.0326,last_cl=0.6185,last=0.0312\n",
      "epis[1800],eps[0.8753],durat[97],fnum=174677,tot_cl=0.4915,tot=0.0323,last_cl=0.4330,last=0.0281\n",
      "epis[1850],eps[0.8705],durat[97],fnum=179531,tot_cl=0.5076,tot=0.0324,last_cl=0.4414,last=0.0288\n",
      "epis[1900],eps[0.8658],durat[97],fnum=184154,tot_cl=0.6468,tot=0.0336,last_cl=3.4434,last=0.0571\n",
      "epis[1950],eps[0.8610],durat[97],fnum=188963,tot_cl=0.6682,tot=0.0338,last_cl=3.6382,last=0.0591\n",
      "epis[2000],eps[0.8562],durat[97],fnum=193806,tot_cl=0.6825,tot=0.0338,last_cl=1.3607,last=0.0373\n",
      "epis[2050],eps[0.8515],durat[97],fnum=198544,tot_cl=0.7524,tot=0.0344,last_cl=2.3942,last=0.0477\n",
      "epis[2100],eps[0.8466],durat[97],fnum=203410,tot_cl=0.7577,tot=0.0343,last_cl=2.2618,last=0.0446\n",
      "epis[2150],eps[0.8418],durat[97],fnum=208244,tot_cl=0.7678,tot=0.0344,last_cl=1.0842,last=0.0330\n",
      "epis[2200],eps[0.8369],durat[97],fnum=213065,tot_cl=0.7852,tot=0.0345,last_cl=1.3627,last=0.0380\n",
      "epis[2250],eps[0.8321],durat[97],fnum=217864,tot_cl=0.8089,tot=0.0347,last_cl=1.6932,last=0.0412\n",
      "epis[2300],eps[0.8272],durat[97],fnum=222774,tot_cl=0.7920,tot=0.0344,last_cl=0.9404,last=0.0332\n",
      "epis[2350],eps[0.8223],durat[97],fnum=227674,tot_cl=0.7663,tot=0.0342,last_cl=-0.1938,last=0.0231\n",
      "epis[2400],eps[0.8174],durat[97],fnum=232602,tot_cl=0.7355,tot=0.0338,last_cl=-0.5633,last=0.0185\n",
      "epis[2450],eps[0.8127],durat[97],fnum=237256,tot_cl=0.7946,tot=0.0343,last_cl=1.4603,last=0.0361\n",
      "epis[2500],eps[0.8078],durat[97],fnum=242236,tot_cl=0.7792,tot=0.0341,last_cl=1.8280,last=0.0409\n",
      "epis[2550],eps[0.8029],durat[97],fnum=247115,tot_cl=0.7728,tot=0.0339,last_cl=0.2398,last=0.0252\n",
      "epis[2600],eps[0.7983],durat[97],fnum=251688,tot_cl=0.8900,tot=0.0350,last_cl=3.6585,last=0.0573\n",
      "epis[2650],eps[0.7934],durat[97],fnum=256568,tot_cl=0.8702,tot=0.0347,last_cl=3.3521,last=0.0536\n",
      "epis[2700],eps[0.7887],durat[97],fnum=261265,tot_cl=0.9503,tot=0.0353,last_cl=2.5180,last=0.0451\n",
      "epis[2750],eps[0.7841],durat[97],fnum=265853,tot_cl=1.0436,tot=0.0363,last_cl=5.6398,last=0.0790\n",
      "epis[2800],eps[0.7794],durat[97],fnum=270619,tot_cl=1.0777,tot=0.0365,last_cl=4.5196,last=0.0691\n",
      "epis[2850],eps[0.7747],durat[97],fnum=275294,tot_cl=1.1414,tot=0.0371,last_cl=3.8296,last=0.0603\n",
      "epis[2900],eps[0.7698],durat[97],fnum=280214,tot_cl=1.1085,tot=0.0367,last_cl=1.9699,last=0.0425\n",
      "epis[2950],eps[0.7649],durat[97],fnum=285120,tot_cl=1.0786,tot=0.0365,last_cl=-0.7113,last=0.0187\n",
      "epis[3000],eps[0.7601],durat[97],fnum=289877,tot_cl=1.1070,tot=0.0368,last_cl=1.0630,last=0.0373\n",
      "epis[3050],eps[0.7554],durat[97],fnum=294603,tot_cl=1.1458,tot=0.0371,last_cl=3.1302,last=0.0555\n",
      "epis[3100],eps[0.7506],durat[97],fnum=299440,tot_cl=1.1490,tot=0.0371,last_cl=2.4090,last=0.0463\n",
      "epis[3150],eps[0.7459],durat[97],fnum=304125,tot_cl=1.2016,tot=0.0376,last_cl=2.9028,last=0.0520\n",
      "epis[3200],eps[0.7413],durat[97],fnum=308685,tot_cl=1.2947,tot=0.0384,last_cl=5.8113,last=0.0810\n",
      "epis[3250],eps[0.7365],durat[97],fnum=313463,tot_cl=1.3133,tot=0.0386,last_cl=4.8327,last=0.0706\n",
      "epis[3300],eps[0.7317],durat[97],fnum=318330,tot_cl=1.3040,tot=0.0385,last_cl=1.6035,last=0.0390\n",
      "epis[3350],eps[0.7268],durat[97],fnum=323167,tot_cl=1.3046,tot=0.0384,last_cl=1.0198,last=0.0326\n",
      "epis[3400],eps[0.7220],durat[97],fnum=327981,tot_cl=1.3135,tot=0.0385,last_cl=1.6242,last=0.0384\n",
      "epis[3450],eps[0.7171],durat[97],fnum=332859,tot_cl=1.3038,tot=0.0383,last_cl=1.2768,last=0.0337\n",
      "epis[3500],eps[0.7124],durat[97],fnum=337604,tot_cl=1.3372,tot=0.0385,last_cl=2.1441,last=0.0409\n",
      "epis[3550],eps[0.7075],durat[97],fnum=342506,tot_cl=1.2844,tot=0.0380,last_cl=0.6157,last=0.0279\n",
      "epis[3600],eps[0.7028],durat[97],fnum=347193,tot_cl=1.3566,tot=0.0387,last_cl=2.0366,last=0.0430\n",
      "epis[3650],eps[0.6981],durat[97],fnum=351949,tot_cl=1.3767,tot=0.0388,last_cl=4.6531,last=0.0689\n",
      "epis[3700],eps[0.6934],durat[97],fnum=356629,tot_cl=1.4194,tot=0.0392,last_cl=3.6780,last=0.0598\n",
      "epis[3750],eps[0.6887],durat[97],fnum=361335,tot_cl=1.4511,tot=0.0395,last_cl=4.1686,last=0.0653\n",
      "epis[3800],eps[0.6838],durat[97],fnum=366157,tot_cl=1.4575,tot=0.0396,last_cl=2.8704,last=0.0525\n",
      "epis[3850],eps[0.6791],durat[97],fnum=370867,tot_cl=1.4875,tot=0.0398,last_cl=2.8509,last=0.0511\n",
      "epis[3900],eps[0.6745],durat[97],fnum=375547,tot_cl=1.5250,tot=0.0402,last_cl=4.0881,last=0.0649\n",
      "epis[3950],eps[0.6700],durat[97],fnum=380005,tot_cl=1.6246,tot=0.0412,last_cl=6.9034,last=0.0916\n",
      "epis[4000],eps[0.6651],durat[97],fnum=384870,tot_cl=1.6174,tot=0.0411,last_cl=5.2222,last=0.0739\n",
      "epis[4050],eps[0.6604],durat[97],fnum=389602,tot_cl=1.6413,tot=0.0413,last_cl=2.3013,last=0.0463\n",
      "epis[4100],eps[0.6557],durat[97],fnum=394335,tot_cl=1.6617,tot=0.0415,last_cl=3.4346,last=0.0571\n",
      "epis[4150],eps[0.6510],durat[97],fnum=399045,tot_cl=1.6885,tot=0.0417,last_cl=3.5982,last=0.0591\n",
      "epis[4200],eps[0.6462],durat[97],fnum=403783,tot_cl=1.7075,tot=0.0419,last_cl=3.5851,last=0.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epis[4250],eps[0.6413],durat[97],fnum=408724,tot_cl=1.6770,tot=0.0415,last_cl=1.2030,last=0.0349\n",
      "epis[4300],eps[0.6365],durat[97],fnum=413533,tot_cl=1.6560,tot=0.0414,last_cl=-0.5105,last=0.0199\n",
      "epis[4350],eps[0.6320],durat[97],fnum=417952,tot_cl=1.7756,tot=0.0425,last_cl=5.9660,last=0.0835\n",
      "epis[4400],eps[0.6273],durat[97],fnum=422682,tot_cl=1.7950,tot=0.0427,last_cl=7.7744,last=0.1011\n",
      "epis[4450],eps[0.6225],durat[97],fnum=427456,tot_cl=1.8036,tot=0.0428,last_cl=3.0178,last=0.0536\n",
      "epis[4500],eps[0.6178],durat[97],fnum=432214,tot_cl=1.8229,tot=0.0429,last_cl=3.0502,last=0.0519\n",
      "epis[4550],eps[0.6133],durat[96],fnum=436724,tot_cl=1.9013,tot=0.0436,last_cl=6.2505,last=0.0829\n",
      "epis[4600],eps[0.6087],durat[96],fnum=441330,tot_cl=1.9475,tot=0.0441,last_cl=7.5528,last=0.0958\n",
      "epis[4650],eps[0.6039],durat[96],fnum=446139,tot_cl=1.9477,tot=0.0440,last_cl=4.0580,last=0.0617\n",
      "epis[4700],eps[0.5990],durat[96],fnum=450964,tot_cl=1.9421,tot=0.0440,last_cl=1.6937,last=0.0389\n",
      "epis[4750],eps[0.5942],durat[96],fnum=455758,tot_cl=1.9457,tot=0.0440,last_cl=1.8519,last=0.0413\n",
      "epis[4800],eps[0.5894],durat[96],fnum=460563,tot_cl=1.9510,tot=0.0440,last_cl=2.3729,last=0.0451\n",
      "epis[4850],eps[0.5848],durat[96],fnum=465233,tot_cl=1.9788,tot=0.0443,last_cl=3.5534,last=0.0583\n",
      "epis[4900],eps[0.5798],durat[96],fnum=470233,tot_cl=1.9355,tot=0.0438,last_cl=1.1897,last=0.0357\n"
     ]
    }
   ],
   "source": [
    "# Whether to render Frames and show the game\n",
    "_render = False\n",
    "while epis_count < max_frame:\n",
    "    mx.nd.waitall()\n",
    "    cum_clipped_reward = 0\n",
    "    cum_reward = 0\n",
    "    env.reset()\n",
    "    next_frame = env.env.render(False)\n",
    "    # next_frame = env.env.get_obs_render(env.env.gen_obs()[\"image\"])\n",
    "    state, current_frame = preprocess(next_frame, image_size, channel, frame_len, initial_state=True)\n",
    "    t = 0.\n",
    "    done = False\n",
    "    initial_state = True\n",
    "    location = [env.env.agent_pos.tolist()]\n",
    "    while not done:\n",
    "        # prepare input\n",
    "        previous_state = state\n",
    "        # show the frame\n",
    "        render_image(current_frame.asnumpy().transpose([1,2,0]), _render)\n",
    "        sample = random.random()\n",
    "        if frame_counter > replay_start_size:\n",
    "            annealing_count += 1\n",
    "        if frame_counter == replay_start_size:\n",
    "            print(\"annealing and learning are started tot = %.4f\" % average)\n",
    "        eps = np.maximum(1. - annealing_count / annealing_end, epsilon_min)\n",
    "        effective_eps = eps\n",
    "        if t < no_op_max:\n",
    "            effective_eps = 1.\n",
    "        step_count = env.env.max_steps - env.env.step_count        \n",
    "        # epsilon greedy policy\n",
    "        if sample < effective_eps:\n",
    "            action = random.randint(0, num_action - 1)\n",
    "        else:\n",
    "            data = [nd.array(state.reshape([1, frame_len * channel, image_size, image_size]), ctx), nd.array([step_count], ctx)]\n",
    "            action = int(nd.argmax(dqn(*data), axis=1).as_in_context(mx.cpu()).asscalar())\n",
    "            \n",
    "        # Skip frame\n",
    "        rew = 0\n",
    "        for skip in range(skip_frame):\n",
    "            next_frame, reward, done, _ = env.step(action)\n",
    "            render_image(next_frame, _render)\n",
    "            cum_clipped_reward += rew_clipper(reward, location)\n",
    "            rew += reward\n",
    "            location.append(env.env.agent_pos.tolist())\n",
    "        cum_reward += rew\n",
    "        \n",
    "        # Reward clipping\n",
    "        reward = rew_clipper(rew, location)\n",
    "        # End Reward clipping\n",
    "        \n",
    "        # _ = env.env.get_obs_render(env.env.gen_obs()[\"image\"])\n",
    "        _ = env.env.render(False)\n",
    "        state, current_frame = preprocess(_, image_size, channel, frame_len, current_state=state) \n",
    "        \n",
    "        # change dtype\n",
    "        _ps = (previous_state * 255.).astype('uint8')\n",
    "        _ac = nd.array([action]).astype('uint8')\n",
    "        _s = (state * 255.).astype('uint8')\n",
    "        _r = nd.array([reward])\n",
    "        _d = nd.array([done])\n",
    "        _sc = nd.array([step_count])\n",
    "        replay_memory.push(_ps, _ac, _s, _r, _d, _sc)\n",
    "\n",
    "        # Train\n",
    "        if frame_counter > replay_start_size and frame_counter % learning_frequency == 0:\n",
    "            batch = replay_memory.sample(batch_size, ctx)\n",
    "            batch_state = batch.state.astype('float32') / 255\n",
    "            batch_state_next = batch.state_next.astype('float32') / 255\n",
    "            batch_action = batch.action\n",
    "            batch_battery  = batch.battery\n",
    "            batch_reward = batch.reward\n",
    "            batch_finish = batch.finish\n",
    "            with autograd.record():\n",
    "                argmax_Q = nd.argmax(dqn(batch_state_next, batch_battery),axis = 1).astype('uint8')\n",
    "                Q_sp = nd.pick(target_dqn(batch_state_next, batch_battery),argmax_Q,1)\n",
    "                Q_sp = Q_sp*(nd.ones(batch_size,ctx = ctx)-batch_finish)\n",
    "                Q_s_array = dqn(batch_state, batch_battery)\n",
    "                Q_s = nd.pick(Q_s_array,batch_action,1)\n",
    "                loss = nd.mean(loss_f(Q_s ,  (batch_reward + gamma *Q_sp)))\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            loss.asscalar()\n",
    "        t += 1\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # Save the model and update Target model\n",
    "        if frame_counter >replay_start_size and frame_counter % target_update == 0:\n",
    "            check_point = frame_counter / (target_update * 100)\n",
    "            file_name = './data/target_%s_%d' % (env_name, int(check_point))\n",
    "            dqn.save_parameters(file_name)\n",
    "            target_dqn.load_parameters(file_name, ctx)\n",
    "        if done:\n",
    "            tot_step.append(t+1)\n",
    "            if epis_count % 50. == 0. :\n",
    "                print('epis[%d],eps[%.4f],durat[%d],fnum=%d,tot_cl=%.4f,tot=%.4f,last_cl=%.4f,last=%.4f' %(epis_count,eps,np.mean(tot_step),frame_counter,average_clipped,average, last_clipped, last))\n",
    "        if frame_counter == 1000000:\n",
    "            np.save(\"frame_count_record_%s_Model_%d\" % (env_name, model_n), frame_count_record)\n",
    "            np.save(\"tot_clipped_reward_%s_Model_%d\" % (env_name, model_n), tot_reward)\n",
    "            np.save(\"tot_reward_%s_Model_%d\" % (env_name, model_n), tot_reward)\n",
    "            np.save(\"tot_step_%s_Model_%d\" % (env_name, model_n), tot_step)\n",
    "            with open(\"./model_%d_memory.pkl\" % model_n, \"wb\") as f:\n",
    "                pickle.dump([list(i) for i in replay_memory.memory], f)  \n",
    "    epis_count += 1\n",
    "    tot_clipped_reward = np.append(tot_clipped_reward, cum_clipped_reward)\n",
    "    tot_reward = np.append(tot_reward, cum_reward)\n",
    "    frame_count_record = np.append(frame_count_record,frame_counter)\n",
    "    if epis_count > 100.:\n",
    "        average_clipped = np.mean(tot_clipped_reward)\n",
    "        average = np.mean(tot_reward)\n",
    "        last_clipped = np.mean(tot_clipped_reward[-100:])\n",
    "        last = np.mean(tot_reward[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dqn.map[0:2](data[0]).shape)\n",
    "print(dqn.map[0:5](data[0]).shape)\n",
    "print(dqn.map[0:8](data[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(replay_memory.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the overall performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epis_count = epis_count - 0\n",
    "bandwidth = 100  # Moving average bandwidth\n",
    "total_clipped = np.zeros(int(num_epis_count) - bandwidth)\n",
    "total_rew = np.zeros(int(num_epis_count) - bandwidth)\n",
    "for i in range(int(num_epis_count) - bandwidth):\n",
    "    total_clipped[i] = np.sum(tot_clipped_reward[i:i + bandwidth]) / bandwidth\n",
    "    total_rew[i] = np.sum(tot_reward[i:i + bandwidth]) / bandwidth\n",
    "t = np.arange(int(num_epis_count) - bandwidth)\n",
    "fig = plt.figure()\n",
    "belplt = plt.plot(t, total_rew[0:int(num_epis_count) - bandwidth], \"r\", label=\"Return\")\n",
    "plt.legend()  #handles[likplt,belplt])\n",
    "print('Running after %d number of episodes' % epis_count)\n",
    "plt.xlabel(\"Number of episode\")\n",
    "plt.ylabel(\"Average Reward per episode\")\n",
    "plt.show()\n",
    "fig.savefig('Assualt_DDQN.png')\n",
    "fig = plt.figure()\n",
    "likplt = plt.plot(t, total_clipped[0:num_episode - bandwidth], \"b\", label=\"Clipped Return\")\n",
    "plt.legend()  #handles[likplt,belplt])\n",
    "plt.xlabel(\"Number of episode\")\n",
    "plt.ylabel(\"Average clipped Reward per episode\")\n",
    "plt.show()\n",
    "fig.savefig('DDQN_Clipped.png')\n",
    "print(max(total_rew[0:int(num_epis_count) - bandwidth]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
