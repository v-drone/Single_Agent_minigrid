{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seventheli/anaconda/lib/python3.8/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.8.0` and `torch==1.10.2+cu102` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import time\n",
    "import logging\n",
    "import gym_minigrid\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "from IPython import display\n",
    "from memory import Memory\n",
    "from utils import preprocess\n",
    "from model.simple_stack import SimpleStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the algorithm\n",
    "#### Update Network\n",
    "* Draw batches of tuples from the replay buffer: $(\\phi,r,a,\\phi')$.\n",
    "* Define the following loss\n",
    "$$\\Large(\\small Q(\\phi,a,\\theta)-r-Q(\\phi',argmax_{a'}Q(\\phi',a',\\theta),\\theta^-)\\Large)^2$$\n",
    "* Where $\\theta^-$ is the parameter of the target network.( Set $Q(\\phi',a',\\theta^-)$ to zero if $\\phi$ is the preprocessed termination state). \n",
    "* Update the $\\theta$\n",
    "* Update the $\\theta^-$ once in a while\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Set the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# frame channel\n",
    "channel = 1\n",
    "# The size of the batch to learn the Q-function\n",
    "batch_size = 8\n",
    "# Resize the raw input frame to square frame of size 80 by 80\n",
    "image_size = 84\n",
    "# Skip 4-1 raw frames between steps\n",
    "skip_frame = 1\n",
    "# The size of replay buffer; set it to size of your memory (.5M for 50G available memory)\n",
    "replay_buffer_size = 20000\n",
    "# With Freq of 1/4-step update the Q-network\n",
    "learning_frequency = 4\n",
    "# Each state is formed as a concatenation 4 step frames [f(t-12),f(t-8),f(t-4),f(t)]\n",
    "frame_len = 32\n",
    "# Update the target network each 10000 steps\n",
    "target_update = 10000\n",
    "# Minimum level of stochasticity of policy (epsilon)-greedy\n",
    "epsilon_min = 0.01\n",
    "# The number of step it take to linearly anneal the epsilon to it min value\n",
    "annealing_end = 1000000.\n",
    "# The discount factor\n",
    "gamma = 0.99\n",
    "# Start to back propagated through the network, learning starts\n",
    "replay_start_size = 50000\n",
    "# Run uniform policy for first 30 times step of the beginning of the game\n",
    "no_op_max = 8\n",
    "# Number episode to run the algorithm\n",
    "num_episode = 10000000\n",
    "max_frame = 200000000\n",
    "# RMSprop learning rate\n",
    "lr = 0.00025\n",
    "# RMSprop gamma1\n",
    "gamma1 = 0.95\n",
    "# RMSprop gamma2\n",
    "gamma2 = 0.95\n",
    "# RMSprop epsilon bias\n",
    "rms_eps = 0.01\n",
    "# Enables gpu if available, if not, set it to mx.cpu()\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'MiniGrid-Empty-Random-6x6-v0'\n",
    "env = gym.make(env_name)\n",
    "num_action = 3\n",
    "manualSeed = 1\n",
    "mx.random.seed(manualSeed)\n",
    "env_name = env_name + \"-Map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = SimpleStack(num_action, frame_len, channel=channel)\n",
    "dqn.collect_params().initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "trainer = gluon.Trainer(dqn.collect_params(), 'RMSProp',\n",
    "                        {'learning_rate': lr, 'gamma1': gamma1, 'gamma2': gamma2, 'epsilon': rms_eps, 'centered': True})\n",
    "dqn.collect_params().zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dqn = SimpleStack(num_action, frame_len, channel=channel)\n",
    "target_dqn.collect_params().initialize(mx.init.Normal(0.02), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = mx.gluon.loss.L2Loss(batch_axis=0)\n",
    "# Counts the number of steps so far\n",
    "frame_counter = 0.\n",
    "# Counts the number of annealing steps\n",
    "annealing_count = 0.\n",
    "# Counts the number episodes so far\n",
    "epis_count = 0.\n",
    "# Initialize the replay buffer\n",
    "replay_memory = Memory(replay_buffer_size, frame_len, channel)\n",
    "tot_clipped_reward = []\n",
    "tot_reward = []\n",
    "frame_count_record = []\n",
    "t_record = []\n",
    "moving_average_clipped = 0.\n",
    "moving_average = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rew_clipper(row, history):\n",
    "    counter = 0\n",
    "    _ = list(reversed(history))[0]\n",
    "    for i in list(reversed(history))[1:]:\n",
    "        if i == _:\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return (row- 0.0001 * counter) * 100\n",
    "\n",
    "def render_image(frame, render):\n",
    "    if render:\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e\n",
    "render_image(preprocess(env.render(False), image_size, channel, frame_len, initial_state=True)[0][-3:].transpose([1,2,0]).asnumpy(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.0025,epis[0],eps[1.000000],durat[144],fnum=144,tot_cl = 0.0000, tot = 0.0000\n",
      "lr:0.0025,epis[50],eps[1.000000],durat[77],fnum=3943,tot_cl = 0.0000, tot = 0.0000\n",
      "lr:0.0025,epis[100],eps[1.000000],durat[74],fnum=7477,tot_cl = 0.0000, tot = 0.0000\n",
      "lr:0.0025,epis[150],eps[1.000000],durat[75],fnum=11354,tot_cl = 47.5499, tot = 0.5046\n",
      "lr:0.0025,epis[200],eps[1.000000],durat[76],fnum=15344,tot_cl = 44.7224, tot = 0.4811\n",
      "lr:0.0025,epis[250],eps[1.000000],durat[78],fnum=19619,tot_cl = 42.0423, tot = 0.4569\n",
      "lr:0.0025,epis[300],eps[1.000000],durat[77],fnum=23215,tot_cl = 43.9635, tot = 0.4751\n"
     ]
    }
   ],
   "source": [
    " # Whether to render Frames and show the game\n",
    "_render = False\n",
    "batch_state = nd.empty((batch_size, frame_len * channel, image_size, image_size), ctx)\n",
    "batch_state_next = nd.empty((batch_size, frame_len * channel, image_size, image_size), ctx)\n",
    "batch_reward = nd.empty([batch_size], ctx)\n",
    "batch_action = nd.empty([batch_size], ctx)\n",
    "batch_done = nd.empty([batch_size], ctx)\n",
    "batch_battery = nd.empty((batch_size, 100), ctx)\n",
    "while epis_count < max_frame:\n",
    "    cum_clipped_reward = 0\n",
    "    cum_reward = 0\n",
    "    env.reset()\n",
    "    next_frame = env.env.render(False)\n",
    "    state, current_frame = preprocess(next_frame, image_size, channel, frame_len, initial_state=True)\n",
    "    t = 0.\n",
    "    done = False\n",
    "    location = [env.env.agent_pos.tolist()]\n",
    "    while not done:\n",
    "        mx.nd.waitall()\n",
    "        previous_state = state\n",
    "        # show the frame\n",
    "        render_image(current_frame.asnumpy().transpose([1,2,0]), _render)\n",
    "        sample = random.random()\n",
    "        if frame_counter > replay_start_size:\n",
    "            annealing_count += 1\n",
    "        if frame_counter == replay_start_size:\n",
    "            print(\"annealing and learning are started tot = %.4f\" % moving_average)\n",
    "        eps = np.maximum(1. - annealing_count / annealing_end, epsilon_min)\n",
    "        effective_eps = eps\n",
    "        if t < no_op_max:\n",
    "            effective_eps = 1.\n",
    "        # epsilon greedy policy\n",
    "        if sample < effective_eps:\n",
    "            action = random.randint(0, num_action - 1)\n",
    "        else:\n",
    "            data = [nd.array(state.reshape([1, frame_len * channel, image_size, image_size]), ctx), nd.array([100 - t], ctx)]\n",
    "            _ = dqn(data)\n",
    "            # print(_.asnumpy().tolist())\n",
    "            action = int(nd.argmax(_, axis=1).as_in_context(mx.cpu()).asscalar())\n",
    "        \n",
    "        next_frame, reward, done, _ = env.step(action)\n",
    "        location.append(env.env.agent_pos.tolist())\n",
    "\n",
    "        cum_reward += reward\n",
    "        \n",
    "        # Reward clipping\n",
    "        reward = rew_clipper(reward, location)\n",
    "        cum_clipped_reward += reward\n",
    "        # End Reward clipping\n",
    "        \n",
    "        # _ = env.env.get_obs_render(env.env.gen_obs()[\"image\"])\n",
    "        _ = env.env.render(False)\n",
    "        \n",
    "        state, current_frame = preprocess(_, image_size, channel, frame_len, initial_state=False)        \n",
    "        replay_memory.push(previous_state, action,  state, reward, done, 100 - t)\n",
    "        render_image(current_frame.asnumpy().transpose([1,2,0]), _render)\n",
    "        # Train\n",
    "        if frame_counter > replay_start_size:\n",
    "            if frame_counter % learning_frequency == 0:\n",
    "                data = replay_memory.sample(batch_size, ctx)\n",
    "                batch_state = nd.empty((batch_size, frame_len * channel, image_size, image_size), ctx)\n",
    "                with autograd.record():\n",
    "                    argmax_Q = nd.argmax(dqn([data.state_next, data.battery]),axis = 1).astype('uint8')\n",
    "                    Q_sp = nd.pick(target_dqn([data.state_next, data.battery]),argmax_Q,1)\n",
    "                    Q_sp = Q_sp*(nd.ones(batch_size,ctx = ctx)-data.finish)\n",
    "                    Q_s_array = dqn([data.state, data.battery])\n",
    "                    Q_s = nd.pick(Q_s_array,data.action,1)\n",
    "                    loss = nd.mean(loss_f(Q_s ,  (data.reward.reshape(batch_size) + gamma *Q_sp)))\n",
    "                loss.backward()\n",
    "                trainer.step(batch_size)\n",
    "        t += 1\n",
    "        frame_counter += 1\n",
    "        # Save the model and update Target model\n",
    "        if frame_counter > replay_start_size:\n",
    "            if frame_counter % target_update == 0:\n",
    "                check_point = frame_counter / (target_update * 100)\n",
    "                file_name = './data/target_%s_%d' % (env_name, int(check_point))\n",
    "                dqn.save_parameters(file_name)\n",
    "                target_dqn.load_parameters(file_name, ctx)\n",
    "                reward_name = './data/tot_rew_DDQN%s_lr_%f' % (env_name, lr)\n",
    "                np.save(reward_name, tot_reward)\n",
    "                reward_name = './data/frame_count_DDQN%s_lr_%f' % (env_name, lr)\n",
    "                np.save(reward_name, frame_count_record)\n",
    "        if done:\n",
    "            t_record.append(t)\n",
    "            if epis_count % 50. == 0.:\n",
    "                print(\"lr:%s,epis[%d],eps[%f],durat[%d],fnum=%d,tot_cl = %.4f, tot = %.4f\"\n",
    "                      % (lr, epis_count, eps, np.mean(t_record), frame_counter, moving_average_clipped, moving_average))\n",
    "    epis_count += 1\n",
    "    tot_clipped_reward = np.append(tot_clipped_reward, cum_clipped_reward)\n",
    "    tot_reward = np.append(tot_reward, cum_reward)\n",
    "    frame_count_record = np.append(frame_count_record, frame_counter)\n",
    "    if epis_count > 100.:\n",
    "        moving_average_clipped = np.mean(tot_clipped_reward[int(epis_count) - 1 - 100:int(epis_count) - 1])\n",
    "        moving_average = np.mean(tot_reward[int(epis_count) - 1 - 100:int(epis_count) - 1])\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "outfile = TemporaryFile()\n",
    "outfile_clip = TemporaryFile()\n",
    "np.save(outfile, moving_average)\n",
    "np.save(outfile_clip, moving_average_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([i.state_next.shape  for i in replay_memory.memory])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the overall performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epis_count = epis_count - 0\n",
    "bandwidth = 100  # Moving average bandwidth\n",
    "total_clipped = np.zeros(int(num_epis_count) - bandwidth)\n",
    "total_rew = np.zeros(int(num_epis_count) - bandwidth)\n",
    "for i in range(int(num_epis_count) - bandwidth):\n",
    "    total_clipped[i] = np.sum(tot_clipped_reward[i:i + bandwidth]) / bandwidth\n",
    "    total_rew[i] = np.sum(tot_reward[i:i + bandwidth]) / bandwidth\n",
    "t = np.arange(int(num_epis_count) - bandwidth)\n",
    "fig = plt.figure()\n",
    "belplt = plt.plot(t, total_rew[0:int(num_epis_count) - bandwidth], \"r\", label=\"Return\")\n",
    "plt.legend()  #handles[likplt,belplt])\n",
    "print('Running after %d number of episodes' % epis_count)\n",
    "plt.xlabel(\"Number of episode\")\n",
    "plt.ylabel(\"Average Reward per episode\")\n",
    "plt.show()\n",
    "fig.savefig('Grid_DDQN.png')\n",
    "fig = plt.figure()\n",
    "likplt = plt.plot(t, total_clipped[0:num_episode - bandwidth], \"b\", label=\"Clipped Return\")\n",
    "plt.legend()  #handles[likplt,belplt])\n",
    "plt.xlabel(\"Number of episode\")\n",
    "plt.ylabel(\"Average clipped Reward per episode\")\n",
    "plt.show()\n",
    "fig.savefig('Grid_Clipped.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
