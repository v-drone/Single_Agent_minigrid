run: DQN
hyper_parameters:
  framework: torch
  double_q: true
  dueling: false
  noisy: false
  exploration_config:
    epsilon_timesteps: 200000
    final_epsilon: 0.01
  num_atoms: 1
  # This is Q hidden, what is for Q computing
  hiddens: [ 512 ]
  replay_buffer_config:
    type: MultiAgentPrioritizedReplayBuffer
    capacity: 100000
  num_steps_sampled_before_learning_starts: 20000
  n_step: 1
  target_network_update_freq: 8000
  lr: .0001
  adam_epsilon: .00015
  rollout_fragment_length: 4
  train_batch_size: 64
  num_gpu: 1
  num_cpus_per_worker: 1
  num_envs_per_worker: 8
  min_sample_timesteps_per_iteration: 10000
